Start 2d-FEM
D = 
5.4e+10 1.8e+10       0
1.8e+10 5.4e+10       0
      0       0 1.8e+10
Parameters done
nel = 2
Coordinates, stiffness, mass, body force done
LM = 
1 2
0 3
1 2
0 3
2 4
3 5
2 4
3 5
Ff = 0
0
0
0
0
K =
  3.6e+10  -3.6e+10         0         0         0
 -3.6e+10   7.2e+10         0  -3.6e+10         0
        0         0  2.16e+11         0 -1.08e+11
        0  -3.6e+10         0   3.6e+10         0
        0         0 -1.08e+11         0  1.08e+11
M =
 331.25 165.625       0       0       0
165.625   662.5       0 165.625       0
      0       0   662.5       0 165.625
      0 165.625       0  331.25       0
      0       0 165.625       0  331.25
Start solving

Qhull output at end
qhull warning: joggle('QJ') always produces simplicial output.  Triangulated output('Qt') does nothing.

Qhull output at end
qhull warning: joggle('QJ') always produces simplicial output.  Triangulated output('Qt') does nothing.

process 0 resident_memory 11.5664 MB, shared_memory 0 MB.
 49.972860s wall, 49.920000s user + 0.010000s system = 49.930000s CPU (99.9%)
[soilblast.colorado.edu:55111] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55111] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
[soilblast.colorado.edu:55114] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55114] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
[soilblast.colorado.edu:55117] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55117] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
[soilblast.colorado.edu:55120] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55120] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
[soilblast.colorado.edu:55123] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55123] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
[soilblast.colorado.edu:55126] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55126] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
[soilblast.colorado.edu:55129] OPAL ERROR: Unreachable in file pmix3x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[soilblast.colorado.edu:55129] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
